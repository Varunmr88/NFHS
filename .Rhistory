mutate(total=`Children aged between 9 and 11 months fully immunized- Male`+`Children aged between 9 and 11 months fully immunized - Female`)%>%group_by(Month,block)%>%summarise_if(is.numeric,sum)->var3
var3
var2%>%select(1:2,contains("full"))%>%
mutate(total=`Children aged between 9 and 11 months fully immunized- Male`+`Children aged between 9 and 11 months fully immunized - Female`)%>%group_by(Month,block)%>%summarise(toim=sum(total))%>%spread(Month,toim)->var3
var3
var2%>%select(1:2,contains("full"))%>%
mutate(total=`Children aged between 9 and 11 months fully immunized- Male`+`Children aged between 9 and 11 months fully immunized - Female`)%>%group_by(block,Month)%>%summarise(toim=sum(total))%>%spread(Month,toim)->var3
var3
View(var2)
library(readxl)
Varun_Analysis <- read_excel("D:/JOB/Suvita/Varun Analysis.xlsx",sheet="Q2.3 HMIS data",range="A1:Y295",na="**")
str(Varun_Analysis)
Varun_Analysis%>%select(1:2,7:25)%>%
pivot_longer(c("Amnour","Baniapur","Chapra","Dariapur","Dighwara","Garkha","Ishupur","Jalalpur","Lahladpur","Maker","Manjhi","Marhaura","Mashrakh","Nagra","Panapur","Parsa","Revelganj","Sonepur","Taraiya"),names_to = "block")%>%
pivot_wider(names_from =`Data Item Name`,values_from=value)%>%
select(1:2,contains("full"))%>%
mutate(total=`Children aged between 9 and 11 months fully immunized- Male`+`Children aged between 9 and 11 months fully immunized - Female`)%>%
group_by(block,Month)%>%
summarise(toim=sum(total))%>%
spread(Month,toim)
library(readxl)
Varun_Analysis <- read_excel("D:/JOB/Suvita/Varun Analysis.xlsx",sheet="Q2.3 HMIS data",range="A1:Y295",na="**")
str(Varun_Analysis)
Varun_Analysis%>%select(1:2,7:25)%>%
pivot_longer(c("Amnour","Baniapur","Chapra","Dariapur","Dighwara","Garkha","Ishupur","Jalalpur","Lahladpur","Maker","Manjhi","Marhaura","Mashrakh","Nagra","Panapur","Parsa","Revelganj","Sonepur","Taraiya"),names_to = "block")%>%
pivot_wider(names_from =`Data Item Name`,values_from=value)%>%
select(1:2,contains("full"))%>%
mutate(total=`Children aged between 9 and 11 months fully immunized- Male`+`Children aged between 9 and 11 months fully immunized - Female`)%>%
group_by(block,Month)%>%
summarise(toim=sum(total))%>%
spread(Month,toim)->var1
View(var1)
library(manipulate)
library(plotly)
library(readxl)
Varun_Analysis <- read_excel("D:/JOB/Suvita/Varun Analysis.xlsx",sheet="Q2.3 HMIS data",range="A1:Y295",na="**")
str(Varun_Analysis)
Varun_Analysis%>%select(1:2,7:25)%>%
pivot_longer(c("Amnour","Baniapur","Chapra","Dariapur","Dighwara","Garkha","Ishupur","Jalalpur","Lahladpur","Maker","Manjhi","Marhaura","Mashrakh","Nagra","Panapur","Parsa","Revelganj","Sonepur","Taraiya"),names_to = "block")%>%
pivot_wider(names_from =`Data Item Name`,values_from=value)%>%
select(1:2,contains("full"))%>%
mutate(total=`Children aged between 9 and 11 months fully immunized- Male`+`Children aged between 9 and 11 months fully immunized - Female`)%>%
group_by(block,Month)%>%
summarise(toim=sum(total))->var1
var1%>%spread(Month,toim)->var2
View(var1)
library(manipulate)
library(plotly)
plot_ly(x=var2$block,y=)
plot_ly(x=var1$block,y=var1$Month)
if(!file.exists("data")){
dir.create("data")
}
fileURL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL,destfile = "./data/pml-training.csv",method = "curl")
fileURL2<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL2,destfile = "./data/pml-testing.csv",method = "curl")
datedoenloaded<-date()
traindata<-read.csv("./data/pml-training.csv")
testdata<-read.csv("./data/pml-testing.csv")
dim(traindata)
dim(testdata)
getwd()
View(head(traindata))
library(dlookr)
library(flextable)
dlookr::describe(iris)%>% flextable()
library(tidyverse)
library(DataExplorer)
str(diamonds)
plot_bar(diamonds)
plot_bar(diamonds,by="cut")
library(SmartEDA)
library(ISLR)
ExpCatViz(
Wage%>%
select(education,jobclass),
target="education")
library(ggstatsplot)
ggbarstats(data=Wage,x=jobclass,y=education,label="both")
library(ggstatsplot)
ggbarstats(data=Wage,x=jobclass,y=education,label="both")
library(ggstatsplot)
ggbarstats(data=Wage,x=jobclass,y=education,label="both")
library(dlookr)
library(flextable)
dlookr::describe(iris)%>% flextable()
iris %>%
group_by(Species)%>%
univar_numeric()
iris %>%
group_by(Species)%>%
diagnose_numeric()%>%
flextable()
library(SmartEDA)
ExpNumStat(iris,by="A",round = 2)%>%
flextable()
ExpNumStat(iris,by="G",gp="Species",round = 2)%>%
flextable()
ExpNumStat(iris,by="GA",gp="Species",Outlier=TRUE,Qnt=c(0.25,0.75),round = 2)%>%
flextable()
library(summarytools)
dfSummary(airquality)
library(gtsummary)
mtcars%>%
select(mpg,hp,am,gear,cyl)%>%
tbl_summary(by=am)%>%
add_p()
library(PerformanceAnalytics)
chart.Correlation(iris%>%
select(-Species),method="kendall")
library(ggplot2)
ggplot(iris, aes(Sepal.Length,Sepal.Width))+
geom_point()+
geom_smooth()+
facet_wrap(~Species)
library(tidyverse)
library(caret)
library(e1071)
library(glmnet)
install.packages("glmnet")
install.packages("MLmetrics")
install.packages("caretEnsemble")
library(tidyverse)
library(caret)
library(e1071)
library(glmnet)
library(MLmetrics)
library(caretEnsemble)
library(kernlab)
#install.packages("DataExplorer")
library(DataExplorer)
create_report(
data = traindata,
output_format = "html_document",
output_file = "report.html",
y="classe"
)
#install.packages("DataExplorer")
library(DataExplorer)
create_report(
data = traindata,
output_format = "html_document",
y="classe"
)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("SmartEDA")
library(SmartEDA)
# similarly, with dplyr syntax: df %>% ExpReport(...)
ExpReport(
df2,
Target="cardio",
label=NULL,
op_file="Report.html",
op_dir=getwd())
# install.packages("tidyverse")
library(dplyr)
library(readr)
df1<-read.csv("cardio_train.txt",header = TRUE,sep=";")
df2<- select(df1,-id)%>%
mutate(age=round(age/365))
#install.packages("SmartEDA")
library(SmartEDA)
# similarly, with dplyr syntax: df %>% ExpReport(...)
ExpReport(
df2,
Target="cardio",
label=NULL,
op_file="Report.html",
op_dir=getwd())
library(SmartEDA)
ExpData(data=traindata,type = 1)
ExpData(data=traindata,type = 2)
traindata2<-traindata[,colMeans(is.na(traindata))<0.9] # removing more than 90%NA
dim(traindata2)
head(traindata2)
traindata2<-traindata2[,-c(1:7)]
nearzerovar<-nearZeroVar(trainingdata2)
nearzerovar<-nearZeroVar(traindata2)
traindata2<-traindata2[,-nearzerovar]
dim(traindata2)
inTrain<-createDataPartition(y=traindata2$classe,p=0.7,list=F)
subtrain<-traindata2[inTrain,]
valid<-subtrain<-traindata2[-inTrain,]
inTrain<-createDataPartition(y=traindata2$classe,p=0.7,list=F)
subtrain<-traindata2[inTrain,]
valid<-subtrain<-traindata2[-inTrain,]
dim(subtrain)
dim(valid)
inTrain<-createDataPartition(y=traindata2$classe,p=0.7,list=F)
subtrain<-traindata2[inTrain,]
valid<-traindata2[-inTrain,]
dim(subtrain)
dim(valid)
control<-trainControl(method="cv", number=3,verboseIter = F)
#Decision Tree
modl_dtree<-train(classe~.,method="rpart",trControl=control,tuneLength=5)
#Decision Tree
modl_dtree<-train(classe~.,data=subtrain,method="rpart",trControl=control,tuneLength=5)
control<-trainControl(method="cv", number=3,verboseIter = F)
#Decision Tree
modl_dtree<-train(classe~.,data=subtrain,method="rpart",trControl=control,tuneLength=5)
fancyRpartPlot(modl_dtree$finalMOdel)
fancyRpartPlot(modl_dtree$finalMOdel)
library(rattle)
control<-trainControl(method="cv", number=3,verboseIter = F)
#Decision Tree
modl_dtree<-train(classe~.,data=subtrain,method="rpart",trControl=control,tuneLength=5)
fancyRpartPlot(modl_dtree$finalMOdel)
fancyRpartPlot(modl_dtree$finalModel)
modl_dtree<-train(classe~.,data=subtrain,method="rpart",trControl=control,tuneLength=5)
fancyRpartPlot(modl_dtree$finalModel)
pre_dtree<-predict(modl_dtree,valid)
cmdtree<-confusionMatrix(pre_dtree,factor(valid$classe))
cmdtree
modlrf<-train(classe~.,data=subtrain,method="rf",trControl=control,tuneLength=5)
library(tidyverse)
library(caret)
library(e1071)
library(glmnet)
library(MLmetrics)
library(caretEnsemble)
library(kernlab)
library(SmartEDA)
library(rattle)
if(!file.exists("data")){
dir.create("data")
}
fileURL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL,destfile = "./data/pml-training.csv",method = "curl")
fileURL2<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL2,destfile = "./data/pml-testing.csv",method = "curl")
datedoenloaded<-date()
traindata<-read.csv("./data/pml-training.csv")
testdata<-read.csv("./data/pml-testing.csv")
dim(traindata)
dim(testdata)
ExpData(data=traindata,type = 1)
traindata2<-traindata[,colMeans(is.na(traindata))<0.9] # removing more than 90%NA
traindata2<-traindata2[,-c(1:7)]
nearzerovar<-nearZeroVar(traindata2)
traindata2<-traindata2[,-nearzerovar]
dim(traindata2)
inTrain<-createDataPartition(y=traindata2$classe,p=0.7,list=F)
subtrain<-traindata2[inTrain,]
valid<-traindata2[-inTrain,]
dim(subtrain)
dim(valid)
control<-trainControl(method="cv", number=3,verboseIter = F)
modl_dtree<-train(classe~.,data=subtrain,method="rpart",trControl=control,tuneLength=5)
fancyRpartPlot(modl_dtree$finalModel)
pre_dtree<-predict(modl_dtree,valid)
cmdtree<-confusionMatrix(pre_dtree,factor(valid$classe))
cmdtree
modlrf<-train(classe~.,data=subtrain,method="rf",trControl=control,tuneLength=5)
pred_rf<-predict(modlrf,valid)
cmrf<-confusionMatrix(pred_rf,valid$classe)
cmrf
cmrf<-confusionMatrix(pred_rf,valid$classe)
cmrf<-confusionMatrix(pred_rf,factor(valid$classe))
cmrf
mdlgbm<-train(classe~.,data=subtrain,method="gbm",trControl=control,tuneLength=5,verbose=F)
pre_gbm<-predict(mdlgbm,valid)
cmgbm<-confusionMatrix(pre_gbm,factor(valid$classe))
cmgbm
modlsvm<-train(classe~.,method="svmLinear",data=subtrain,trControl=control,tuneLength=5,verbose=F)
pred_svm<-predict(modlsvm,valid)
cmsvm<-confusionMatrix(pred_svm,factor(valid$classe))
cmsvm
library(ISLR);library(ggplot2);library(caret)
data(wage)
train1<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training1<-Wage[train1,]
testing1<-Wage[-train1,]
dim(training1);dim(testing1)
dim(Wage)
featurePlot(x=training1[,c("age","education","jobclass")],
y=training1$wage,
plot="pairs")
qplot(age,wage,data=training1)
qplot(age,wage,data=training1,colour=jobclass)
q<-qplot(age,wage,colour=education,data=training1)
q+geom_smooth(method=lm,formula = y~x)
q
#Boxplots with cut2
library(Hmisc)
library(survival)
library(ggplot2)
library(gridExtra)
cutWage<-cut2(training1$wage,g=4)
bp1<-qplot(cutWage,age,data = training1,fill=cutWage)
bp1<-bp1+geom_boxplot()
bp2<-qplot(cutWage,age,data=training1,fill=cutWage)
bp2<-bp2+geom_boxplot()
bp2<-bp2+geom_jitter(cex=1.2)
grid.arrange(bp1,bp2,ncol=2)
qplot(wage,colour=education,data=training1,geom="density")
cmsvm$overall["Accuracy"]
View(cmgbm)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
mdlrf<-train(y~.,method="rf",data=vowel.train)
prerf<-predict(mdlrf,vowel.test)
confusionMatrix(vowel.test$y,prerf)
mdlgbm<-train(y~.,method="gbm",data=vowel.train,verbose=FALSE)
predgbm<-predict(mdlgbm,vowel.test)
confusionMatrix(vowel.test$y,predgbm)
agreed<-prerf==predgbm
confusionMatrix(vowel.test$y[agreed],prerf[agreed])
varImp(mdl)
cmsvm$overall["Accuracy"]
cmgbm$overall["Accuracy"]
cmrf$overall["Accuracy"]
cmdtree$overall["Accuracy"]
finalpred<-predict(modlrf,testdata)
finalpred
SVM Model<-cmsvm$overall["Accuracy"]
GBMModel<-cmgbm$overall["Accuracy"]
RandomForestModel<-cmrf$overall["Accuracy"]
DecisionTreeModel<-cmdtree$overall["Accuracy"]
ans<-cbind(SVMModel,GBMModel,RandomForestModel,DecisionTreeModel)
SVMModel<-cmsvm$overall["Accuracy"]
ans<-cbind(SVMModel,GBMModel,RandomForestModel,DecisionTreeModel)
ans
mdlgbm<-train(classe~.,data=subtrain,method="gbm",trControl=control,tuneLength=5,verbose=F)
pre_gbm<-predict(mdlgbm,valid)
cmgbm<-confusionMatrix(pre_gbm,factor(valid$classe))
View(cmgbm)
mdlgbm<-train(classe~.,data=subtrain,method="gbm",trControl=control,tuneLength=5,verbose=F)
library(tidyverse)
library(caret)
library(e1071)
library(glmnet)
library(MLmetrics)
library(caretEnsemble)
library(kernlab)
library(SmartEDA)
library(rattle)
mdlgbm<-train(classe~.,data=subtrain,method="gbm",trControl=control,tuneLength=5,verbose=F)
mdlgbm<-train(classe~.,data=subtrain,method="gbm",trControl=control,tuneLength=5,verbose=F)
traindata2<-traindata[,colMeans(is.na(traindata))<0.9] # removing more than 90%NA
if(!file.exists("data")){
dir.create("data")
}
fileURL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL,destfile = "./data/pml-training.csv",method = "curl")
fileURL2<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL2,destfile = "./data/pml-testing.csv",method = "curl")
datedoenloaded<-date()
traindata<-read.csv("./data/pml-training.csv")
testdata<-read.csv("./data/pml-testing.csv")
dim(traindata)
dim(testdata)
ExpData(data=traindata,type = 1)
nearzerovar<-nearZeroVar(traindata2)
traindata2<-traindata[,colMeans(is.na(traindata))<0.9] # removing more than 90%NA
traindata2<-traindata2[,-c(1:7)]
nearzerovar<-nearZeroVar(traindata2)
traindata2<-traindata2[,-nearzerovar]
dim(traindata2)
inTrain<-createDataPartition(y=traindata2$classe,p=0.7,list=F)
subtrain<-traindata2[inTrain,]
valid<-traindata2[-inTrain,]
dim(subtrain)
dim(valid)
control<-trainControl(method="cv", number=3,verboseIter = F)
modlrf<-train(classe~.,data=subtrain,method="rf",trControl=control,tuneLength=5)
mdlgbm<-train(classe~.,data=subtrain,method="gbm",trControl=control,tuneLength=5,verbose=F)
pre_gbm<-predict(mdlgbm,valid)
cmgbm<-confusionMatrix(pre_gbm,factor(valid$classe))
View(cmgbm)
shiny::runApp('D:/Data Science/R/John Hopkins/Data Products/DataProducts')
runApp('D:/Data Science/R/John Hopkins/Data Products/DataProducts')
runApp('D:/Data Science/R/John Hopkins/Data Products/DataProducts')
runApp('D:/Data Science/R/John Hopkins/Data Products/DataProducts')
runApp('D:/Data Science/R/John Hopkins/Data Products/DataProducts')
runApp('D:/Data Science/R/John Hopkins/Data Products/DataProducts')
runApp('D:/Data Science/R/John Hopkins/Data Products/DataProducts')
runApp('D:/Data Science/R/John Hopkins/Data Products/DataProducts')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runExample("11_timer")
runExample("10_download")
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Rlearn')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny')
library(shiny)
library(shiny)
selectInput(
inputid='dropdown',label = "please make selection",
choices=list('value1'=1,
'value2'=2,
'value3'=3,
)
)
library(shiny)
selectInput(
inputId='dropdown',label = "please make selection",
choices=list('value1'=1,
'value2'=2,
'value3'=3
)
)
shiny::runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
head(var1)
library(readxl)
Varun_Analysis <- read_excel("D:/JOB/Suvita/Varun Analysis.xlsx",sheet="Q2.3 HMIS data",range="A1:Y295",na="**")
str(Varun_Analysis)
Varun_Analysis%>%select(1:2,7:25)%>%
pivot_longer(c("Amnour","Baniapur","Chapra","Dariapur","Dighwara","Garkha","Ishupur","Jalalpur","Lahladpur","Maker","Manjhi","Marhaura","Mashrakh","Nagra","Panapur","Parsa","Revelganj","Sonepur","Taraiya"),names_to = "block")%>%
pivot_wider(names_from =`Data Item Name`,values_from=value)%>%
select(1:2,contains("full"))%>%
mutate(total=`Children aged between 9 and 11 months fully immunized- Male`+`Children aged between 9 and 11 months fully immunized - Female`)%>%
group_by(block,Month)%>%
summarise(toim=sum(total))->var1
var1%>%spread(Month,toim)->var2
head(var1)
library(readxl)
Varun_Analysis <- read_excel("D:/JOB/Suvita/Varun Analysis.xlsx",sheet="Q2.3 HMIS data",range="A1:Y295",na="**")
str(Varun_Analysis)
Varun_Analysis%>%select(1:2,7:25)%>%
pivot_longer(c("Amnour","Baniapur","Chapra","Dariapur","Dighwara","Garkha","Ishupur","Jalalpur","Lahladpur","Maker","Manjhi","Marhaura","Mashrakh","Nagra","Panapur","Parsa","Revelganj","Sonepur","Taraiya"),names_to = "block")%>%
pivot_wider(names_from =`Data Item Name`,values_from=value)%>%
select(1:2,contains("full"))%>%
mutate(total=`Children aged between 9 and 11 months fully immunized- Male`+`Children aged between 9 and 11 months fully immunized - Female`)%>%
group_by(block,Month)%>%
summarise(toim=sum(total))->var1
var1%>%spread(Month,toim)->var2
head(var1)
ggplot(var1,aes(x=block,y=toim,color=MOnth))+
geom_bar()
library(readxl)
Varun_Analysis <- read_excel("D:/JOB/Suvita/Varun Analysis.xlsx",sheet="Q2.3 HMIS data",range="A1:Y295",na="**")
str(Varun_Analysis)
Varun_Analysis%>%select(1:2,7:25)%>%
pivot_longer(c("Amnour","Baniapur","Chapra","Dariapur","Dighwara","Garkha","Ishupur","Jalalpur","Lahladpur","Maker","Manjhi","Marhaura","Mashrakh","Nagra","Panapur","Parsa","Revelganj","Sonepur","Taraiya"),names_to = "block")%>%
pivot_wider(names_from =`Data Item Name`,values_from=value)%>%
select(1:2,contains("full"))%>%
mutate(total=`Children aged between 9 and 11 months fully immunized- Male`+`Children aged between 9 and 11 months fully immunized - Female`)%>%
group_by(block,Month)%>%
summarise(toim=sum(total))->var1
var1%>%spread(Month,toim)->var2
head(var1)
ggplot(var1,aes(x=block,y=toim,color=Month))+
geom_bar()
ggplot(data=var1,aes(x=block,y=toim,color=Month))+
geom_bar(stat = "count")
ggplot(data=var1,aes(x=block,y=toim,color=Month))+
geom_bar(stat = "sum")
ggplot(data=var1,aes(x=block,y=toim,color=Month))+
geom_bar(stat = "identity")
ggplot(data=var1,aes(x=block,y=toim,colour=Month))+
geom_bar(stat = "identity")
ggplot(data=var1,aes(x=block,y=toim)+
ggplot(data=var1,aes(x=block,y=toim)+
ggplot(data=var1,aes(x=block,y=toim))+
geom_bar(stat = "identity",aes(fill=Month))
var3%>%filter(block=="Amnour")
var3%>%filter(block=="Amnour")
var3<-var1%>%filter(block=="Amnour")
ggplot(data=var3,aes(x=Month,y=toim))+
geom_bar(stat = "identity",aes(fill=Month))
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
install.packages("wesanderson")
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
shinyApp(ui, server)
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
install.packages('rsconnect')
install.packages("rsconnect")
library(rsconnect)
rsconnect::setAccountInfo(name='fdujxa-varun-m0r',
token='61412EA40E5D6ECE0CBCF239A269AC97',
secret='<SECRET>')
rsconnect::setAccountInfo(name='fdujxa-varun-m0r',
token='61412EA40E5D6ECE0CBCF239A269AC97',
secret='<SECRET>')
rsconnect::setAccountInfo(name='fdujxa-varun-m0r',
token='61412EA40E5D6ECE0CBCF239A269AC97',
secret='<SECRET>')
rsconnect::setAccountInfo(name='fdujxa-varun-m0r',
token='61412EA40E5D6ECE0CBCF239A269AC97',
secret='MRXyqpQfOuzTixoHfDL+AYQD7ajQMKskj/FJBjiN')
shiny::runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/hmis')
shiny::runApp('D:/Data Science/R/John Hopkins/Data Products/Shiny/nfhs')
getwd()
setwd("D:/Data Science/R/John Hopkins/Data Products/Shiny/nfhs")
runApp()
